# 将 Google Neural MIP 方法迁移到测试性优化：实施指南

> 本文档提炼自 Google 《Solving Mixed Integer Programs Using Neural Networks》一文，结合本仓库的测点优化（testability optimization）场景，总结落地步骤与工程要点，帮助你从论文到可运行程序的全流程实现。

## 1. 目标与整体架构

在测试性优化问题中，我们需要在海量候选测试动作中选择最优子集，以满足故障可检测性/可隔离性约束，并最小化测试成本。这类问题可建模为混合整数规划（MIP）：

- **整数变量**：是否选择某个测试列（0/1）；
- **约束**：检测覆盖、隔离判定、资源或时间限制等；
- **目标**：综合测试成本、执行时间或权重。

Google 方案将学习型启发式嵌入 MIP 求解器中，以加速获得高质量解并缩小最优性间隙：

1. **Neural Diving（神经下潜）**：学习生成部分变量赋值，缩小问题规模，快速找到好解；
2. **Neural Branching（神经分支）**：学习在分支定界树中选择分支变量，降低搜索树规模，加速收敛。

两者组合成针对特定数据集定制的 **Neural Solver**，见下图概念流程：

```
原始测试性 MIP → (Neural Diving 生成子问题) → (SCIP/CP-SAT 并行求解) → 候选可行解
                   ↓
         Neural Branching 嵌入求解器 → 更小的搜索树/更快的界
```

## 2. 数据准备与问题建模

1. **统一数据接口**：使用 `core/data_io.py` 中的数据生成或实际测点数据导入，构建矩阵 `D`（覆盖关系）、故障概率 `p`、测试成本 `c`、阈值 `τ_d, τ_i` 等。
2. **MIP 建模**：复用 `experiments/ilp_cp_sat.py`（CP-SAT）或扩展至 SCIP：
   - 变量：`x_j ∈ {0,1}` 表示是否选测试 `j`；必要时增加连续辅助变量。
   - 约束：检测/隔离可通过线性不等式表示；可结合故障概率、覆盖矩阵等。
   - 目标：例如 `min Σ c_j x_j`，可拓展为权重和或风险加权成本。
3. **求解接口**：确保求解器能返回：可行性标志、目标值、任意时刻轨迹（用于评估）、最终选择向量 `x`。参照 `solve_tp_mip_cp_sat` 的返回结构。

## 3. Neural Diving 实施步骤

Neural Diving 关键是把“生成测试选择提示”视为条件生成问题：

### 3.1 训练数据采集

1. **Teacher 求解**：在训练实例集上运行基线求解器（无提示）得到高质量解 `x*`。可使用：
   ```python
   sol = solve_tp_mip_cp_sat(D, fault_probs, test_costs, tau_d, tau_i, time_limit_s, x_hint=None)
   x_star = sol["selected"]
   ```
2. **特征设计**：针对每列测试构造与上下文无关或弱依赖的特征。例如 `experiments/features.py` 中的 `per_test_features` 已实现：
   - 覆盖权重、测试成本、隔离增益等；
   - 可扩展加入：历史选择频次、故障类型嵌入、领域规则等。
3. **样本构造**：将每个测试列视为一个样本，标签为 `x*_j`。如果采用上下文特征（比如已选集合 `ctx`），需同步存储。

### 3.2 模型训练

1. **模型结构**：选择轻量 MLP 或图神经网络（GNN）。本仓库示例 `TinyMLP`（两层全连接）即可快速验证。
2. **输入规范化**：对特征做均值方差归一化，避免不同尺度影响。
3. **损失函数**：可使用二元交叉熵或均方误差逼近 `x*_j`；
4. **训练配置**：根据数据量设置 epoch、batch、学习率；监控验证集（留出部分训练实例）上的 AUC/F1，确保模型能区分重要与非重要测试。

### 3.3 生成 Hint / 部分赋值

推理时，根据预测分数生成提示向量 `h`：

```python
scores = net.predict((feats - mu) / sd)
prob = sigmoid(scores)
hint = (prob >= θ).astype(int)
if hint.sum() == 0:
    # 兜底策略：选性价比最高的列
    hint[argmax((w_cov + sep_gain)/(cost + ε))] = 1
```

- 阈值 `θ` 可以设置多个版本（如 0.3 / 0.5 / 0.7），分别生成不同的子问题。
- 也可输出软提示（概率）供 CP-SAT 的 `AddHint` 或 SCIP 的 `scip_apply_sol` 使用。

### 3.4 子 MIP 求解与并行

1. **子问题定义**：将 `hint` 中为 1 的变量固定为已选，或通过约束/提示优先探索这些变量；
2. **求解方式**：
   - **并行**：为每组提示启动独立求解进程，取最佳解（需要资源充足时）；
   - **串行**：在同一时间预算下顺序尝试各提示，确保公平比较；
3. **结果评估**：记录成本、求解时间、可行性和 anytime 轨迹，用箱线图、曲线对比无提示基线。`experiments/utils.py` 提供 `anytime_plot`、`boxplot_pair` 示例。

## 4. Neural Branching 集成流程

Neural Branching 目标是学习在分支定界树中选择变量，缩小搜索树：

### 4.1 数据收集：ADMM Full Strong Branching（FSB）

1. **专家策略**：实现基于 ADMM 的批量 FSB（论文第 7.1.1 节），对每个候选变量模拟左右分支的 LP 松弛提升，得到打分；
2. **GPU 批处理**：采用 `scipy`/`pytorch` 或自定义 CUDA 内核实现批量 ADMM 解 LP，减少大规模实例的数据生成时间；
3. **日志记录**：对每个分支节点保存：
   - 节点 LP 解与松弛目标值；
   - 每个候选变量的特征（参照 Gasse et al. 2019 结构）；
   - 专家选择的分支变量索引。

### 4.2 图神经网络模型

1. **输入表示**：把 MIP 表示为二部图（变量节点 `V`、约束节点 `C`、非零系数作为边特征），附加：
   - 变量上下界、类型、LP 松弛解、约束 RHS 等；
   - 当前节点深度、历史剪枝统计作为全局特征。
2. **网络结构**：论文使用 Graph Convolutional Network（GCN），每层执行变量-约束-变量信息传递；可参考 Gasse et al. 的开源实现。
3. **输出**：对候选变量输出 softmax 概率，训练时用交叉熵模仿专家决策；
4. **训练细节**：
   - 批量随机采样树节点，保持类别平衡；
   - 使用学习率调度、梯度裁剪，确保稳定；
   - 验证指标：top-1 / top-k 精度、预估树节点数（可通过离线重放测量）。

### 4.3 与求解器联动

1. **SCIP 集成**：在分支回调中调用训练好的网络，使用 GPU/CPU 加速推理；当网络置信度低或超时，可回退到默认策略（可靠伪成本）。
2. **CP-SAT 集成**：如果使用 CP-SAT，替换或引导其变量选择策略（例如通过 `DecisionStrategyProto` 中的 `phase`/`activity`）
3. **安全措施**：
   - 设置时间预算或节点深度阈值，避免学习策略拖慢求解；
   - 保留求解器自带启发式和剪枝策略，确保最坏情况性能。

## 5. 评估指标与实验设计

1. **数据划分**：保持训练/验证/测试实例互斥，如论文中采用 70/15/15 或按日期/产品线划分。
2. **性能指标**：
   - **原始指标**：平均测试成本、故障覆盖率、运行时间、可行率；
   - **MIP 指标**：Primal gap、Dual gap、Primal-Dual gap；
   - **生存曲线**：在时间轴上统计达到目标 gap 的实例比例。
3. **对照组**：
   - 无提示基线（纯 CP-SAT / SCIP）；
   - 传统启发式（曼哈顿距离 / pattern DB 等，可借鉴 15-puzzle 研究对比）；
   - 不同提示阈值、不同分支策略组合。
4. **统计稳健性**：对随机种子取 `{1,...,5}`，对结果做均值与箱线图展示，遵循论文中“calibrated time”概念确保时间统计公平。

## 6. 与 15-Puzzle 神经启发式的类比与启示

开源项目 15-Puzzle-Neural-Approach 以及后续研究提供了启发：

- **任务映射**：15 拼图中的启发函数对应这里的“测试列优先级”预测；
- **神经 A***：其流程为“NN 估计 → A* 搜索”，与“NN 提示 → MIP 求解”结构一致；
- **实验实践**：
  - 先训练 NN 估计每个移动的残余代价，相当于本任务中预测每个测试的重要性；
  - 将 NN 输出作为启发函数/优先级，能在搜索树更深处大幅提速；
  - 对比多种启发式（曼哈顿、线性冲突等），强调混合启发式优势，启发我们在特征工程时组合覆盖度、隔离增益、成本等多信号。

## 7. 落地路线图（建议）

1. **阶段 0：基线复现**
   - 使用现有 `step1_reproduce.py`、`step2_neural_mip.py` 跑通随机数据，熟悉数据结构与接口。
2. **阶段 1：Neural Diving MVP**
   - 收集真实/仿真测点数据，训练 TinyMLP；
   - 集成 hint 到 CP-SAT `AddHint` 或 SCIP `set_hint()`；
   - 对比成本、运行时间、anytime 曲线，确认收益。
3. **阶段 2：增强模型与特征**
   - 引入上下文特征（例如当前 hint 已选集合、覆盖剩余度）；
   - 尝试 GNN、Transformer 结构，提升泛化能力。
4. **阶段 3：Neural Branching**
   - 实现 ADMM-FSB 数据生成管线；
   - 训练 GCN 分支策略，嵌入求解器；
   - 与 Neural Diving 组合测试，验证对 gap 和时间的提升。
5. **阶段 4：工程化与监控**
   - 构建实验追踪（参数、数据版本、模型权重）；
   - 建立指标看板与回归测试，确保模型迭代不会退化；
   - 设计回退机制，保证系统在模型失效时仍可使用默认求解。

## 8. 注意事项

- **数据分布漂移**：当测试场景或设备组合变化，需重新收集训练数据并微调模型。
- **可解释性**：对高风险工业应用，可输出测试列的选择概率、特征贡献，辅助审核。
- **资源预算**：Neural Branching 数据生成耗时巨大，可优先实现 Neural Diving，在收益确认后再投入。
- **持续学习**：通过在线收集求解日志（提示 → 结果），定期增量训练提升性能。

---

通过以上步骤，可以系统地将 Google 的 Neural MIP 方法迁移并定制到测试性优化领域，实现学习驱动的测点选取加速与性能提升。
